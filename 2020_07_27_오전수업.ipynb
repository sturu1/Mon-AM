{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020_07_27_오전수업.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNOIEEeRerq9kCGhfPRPkI3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sturu1/Mon-AM/blob/master/2020_07_27_%EC%98%A4%EC%A0%84%EC%88%98%EC%97%85.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1DiWfumy5gF",
        "colab_type": "text"
      },
      "source": [
        "## Funtional API를 사용하기 위한 기본 Setup\n",
        "외워야함. 익히면 편함\n",
        "\n",
        "https://chloevan.github.io/python/tensorflow2.0/ch8_2_transfer_learning/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFD4hb5jtCIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lgyJmiPEdrI",
        "colab_type": "text"
      },
      "source": [
        "#sequential 을 Funtional로 바꿀수잇어야함\n",
        "#shape (32, 32, 3) (x, y , 채널)\n",
        "#784는 28 * 28 을 펼쳐  놓은것\n",
        "#funtional은 input 데이터 모양은 정해져야한다. \n",
        "#epoch는 책1권, batch_size는 1단원, Dense ,  중간층엔 activation 이  ,출력 activation 은  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3xjTB3B4Ee5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "d480b237-007c-448a-fd24-1bd8cae75887"
      },
      "source": [
        "#Funtional API를 사용하려면 \n",
        "#우선  input node를 항상 먼저 설정해줘야한다.\n",
        "inputs = keras.Input(shape=(784, ))#입력노드\n",
        "print(inputs.shape, inputs.dtype)\n",
        "\n",
        "dense = layers.Dense(64, activation='relu')#은닉층노드\n",
        "x = dense(inputs)\n",
        "outputs = layers.Dense(10)(x)#출력노드\n",
        "#=======그래프모델이 정의됨\n",
        "\n",
        "model = keras.Model(inputs = inputs, outputs = outputs, name = 'mnist_model')#처음inputs , outputs는 변수이다. 뒤에꺼는 입력노드, 출력노드이다.\n",
        "model.summary()\n",
        "\n",
        "keras.utils.plot_model(model, \"my_first_model.png\")#그래프로 가시화"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 784) <dtype: 'float32'>\n",
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYmCDrpyG3GH",
        "colab_type": "text"
      },
      "source": [
        "# 트레이닝, 평가, 추론\n",
        "\n",
        "1. 트레이닝, 평가, 추론 작업은 Sequential 모델링 방법과 동일하게 사용가능\n",
        "2. MNIST로딩, 벡터 reshape, 모델fit, evaluation순이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3ejjgDUErFN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "8ccca687-d0ef-47be-ed65-bdda6d0aee3d"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
        "\n",
        "model.compile(loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              optimizer = keras.optimizers.RMSprop(),\n",
        "              metrics = [\"accuracy\"])\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size = 64, epochs = 2, validation_split = 0.2)\n",
        "\n",
        "test_scores = model.evaluate(x_test, y_test, verbose = 2)\n",
        "print(\"test loss\", test_scores[0])\n",
        "print(\"test accuracy\", test_scores[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.3742 - accuracy: 0.8959 - val_loss: 0.2130 - val_accuracy: 0.9388\n",
            "Epoch 2/2\n",
            "750/750 [==============================] - 2s 2ms/step - loss: 0.1921 - accuracy: 0.9445 - val_loss: 0.1626 - val_accuracy: 0.9529\n",
            "313/313 - 0s - loss: 0.1638 - accuracy: 0.9533\n",
            "test loss 0.16380411386489868\n",
            "test accuracy 0.9532999992370605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfvaeVRTKE2v",
        "colab_type": "text"
      },
      "source": [
        "# 모델 저장(save) 및 직렬화(serialize)\n",
        "\n",
        "1. 저장된 파일은 아래와 같은 정보들로 저장됨\n",
        "*  model architecture\n",
        "*  model weight values\n",
        "*  model training config\n",
        "*  optimizer and its state "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-BxAyE8IeLC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "b3406c6b-17c0-45d9-9a56-77aa57dee952"
      },
      "source": [
        "model.save(\"path_to_my_model\")\n",
        "\n",
        "model = keras.models.load_model(\"path_to_my_model\")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: path_to_my_model/assets\n",
            "Model: \"mnist_model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_18 (InputLayer)        [(None, 784)]             0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83e5kpyVOnk2",
        "colab_type": "text"
      },
      "source": [
        "# 여러개의 모델정의를 위해 같은 그래프레이어 사용하기\n",
        "\n",
        "* 전체 오토인코더 모델에서 인코더 모델과 오토인코더모델 두 개의 모델 생성해보기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6ePFeyrLTOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "03abcc76-beb1-468e-aa05-9d9f66e0f290"
      },
      "source": [
        "encoder_input = keras.Input(shape = (28, 28, 1), name = \"img\")\n",
        "x = layers.Conv2D(16, 3, activation = 'relu')(encoder_input)\n",
        "x = layers.Conv2D(32, 3, activation = 'relu')(x)\n",
        "x = layers.MaxPooling2D(3)(x)\n",
        "x = layers.Conv2D(32, 3, activation = 'relu')(x)\n",
        "x = layers.Conv2D(16, 3, activation = 'relu')(x)\n",
        "encoder_output = layers.GlobalMaxPooling2D()(x)\n",
        "#model1\n",
        "encoder = keras.Model(encoder_input, encoder_output, name = \"encoder\")\n",
        "\n",
        "encoder.summary()\n",
        "\n",
        "x = layers.Reshape((4, 4, 1))(encoder_output)\n",
        "x = layers.Conv2DTranspose(16, 3, activation =  'relu')(x)\n",
        "x = layers.Conv2DTranspose(32, 3, activation =  'relu')(x)\n",
        "x = layers.UpSampling2D(3)(x)\n",
        "x = layers.Conv2DTranspose(16, 3, activation =  'relu')(x)\n",
        "decoder_output = layers.Conv2DTranspose(1, 3, activation = 'relu')(x)\n",
        "\n",
        "#model2\n",
        "autoencoder = keras.Model(encoder_input, decoder_output, name = \"autoencoder\")\n",
        "autoencoder.summary()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 32)          9248      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 16)          4624      \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 16)                0         \n",
            "=================================================================\n",
            "Total params: 18,672\n",
            "Trainable params: 18,672\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model: \"autoencoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "img (InputLayer)             [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 26, 26, 16)        160       \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 24, 24, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 32)          9248      \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 16)          4624      \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d_1 (Glob (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 4, 4, 1)           0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTr (None, 6, 6, 16)          160       \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTr (None, 8, 8, 32)          4640      \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_5 (Conv2DTr (None, 26, 26, 16)        4624      \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_6 (Conv2DTr (None, 28, 28, 1)         145       \n",
            "=================================================================\n",
            "Total params: 28,241\n",
            "Trainable params: 28,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UtpGKFWAPw0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}